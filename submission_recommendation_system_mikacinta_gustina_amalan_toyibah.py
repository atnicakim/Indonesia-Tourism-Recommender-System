# -*- coding: utf-8 -*-
"""Submission_Recommendation System_Mikacinta Gustina Amalan Toyibah

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y7xCkVpV1fPdSqTCwkZeDVghrapmdevM

# Indonesia Tourism Destination Recommender

Pariwisata merupakan salah satu sektor strategis dalam pembangunan ekonomi Indonesia. Berdasarkan data Badan Pusat Statistik (BPS), jumlah perjalanan wisatawan nusantara (wisnus) pada tahun 2023 mencapai 741,82 juta perjalanan, meningkat 11,45% dibandingkan tahun sebelumnya. Sementara itu, jumlah kunjungan wisatawan mancanegara (wisman) juga mengalami peningkatan signifikan. Hingga Oktober 2023, total kunjungan mencapai hampir 9,5 juta, melampaui target tahunan sebesar 8,5 juta kunjungan. Informasi ini disampaikan oleh Kementerian Pariwisata dan Ekonomi Kreatif (Kemenparekraf) dalam siaran pers resmi. Namun demikian, data menunjukkan bahwa kunjungan wisatawan—baik domestik maupun mancanegara—masih terkonsentrasi di destinasi wisata populer seperti Bali, Yogyakarta, dan Bandung. Dalam laporan "Statistik Wisatawan Nusantara 2023", provinsi-provinsi dengan infrastruktur dan promosi wisata yang kuat mendominasi jumlah perjalanan. Hal ini mengindikasikan adanya ketimpangan distribusi wisatawan, yang dapat menimbulkan fenomena overtourism di satu sisi, dan kurangnya eksposur terhadap destinasi potensial di sisi lainnya.

Di sisi lain, dengan semakin meluasnya akses internet, sebagian besar wisatawan kini merencanakan perjalanannya secara mandiri. Berdasarkan laporan Google Travel Trends 2023, sebanyak 68% wisatawan Indonesia mencari inspirasi wisata melalui internet. Namun, 52% di antaranya merasa kewalahan karena terlalu banyak pilihan informasi yang tersedia secara daring (information overload). Akibatnya, calon wisatawan justru mengalami kesulitan dalam menentukan tujuan yang sesuai dengan preferensi dan kebutuhan mereka. Kondisi tersebut menegaskan pentingnya pemanfaatan teknologi cerdas untuk membantu wisatawan dalam proses pengambilan keputusan. Teknologi seperti recommender system berbasis kecerdasan buatan (Artificial Intelligence) dapat menjadi solusi untuk memberikan rekomendasi destinasi wisata yang personal dan relevan bagi setiap individu.

- Bagaimana cara membantu wisatawan dalam menemukan destinasi wisata yang sesuai dengan preferensi pribadi mereka secara efisien?
- Bagaimana cara memberikan rekomendasi 10 destinasi wisata terbaik di kota-kota Indonesia, yang sesuai dengan preferensi destinasi pengguna?

Untuk  menjawab pertanyaan tersebut, dibuatlah sistem rekomendasi dengan tujuan atau goals sebagai berikut:
- Mengembangkan sistem rekomendasi destinasi wisata yang dapat memberikan hasil personalisasi berdasarkan konten deskripsi destinasi dan preferensi pengguna dengan teknik Content-based Filtering dan Collaborative Filtering
- Memberikan top-10 rekomendasi sesuai dengan preferensi destinasi serupa.

## Sumber Data
[Indonesia Tourism Destinantion Data](https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination/data)

# Data Understanding
"""

from google.colab import drive
drive.mount('/content/drive')

"""Melakukan mount data Drive"""

from google.colab import files
files.upload()

"""Mengimpor dataset csv (4 file csv)

Terdapat 4 file csv yang digunakan, meliputi file user, paket teourism, rating tourism, dan juga list tempat dengan id nya.
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from sklearn.feature_extraction.text import CountVectorizer
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Load dataset utama
wisata = pd.read_csv("tourism_with_id.csv")
rating = pd.read_csv("tourism_rating.csv")
user = pd.read_csv("user.csv")
package = pd.read_csv("package_tourism.csv")


# Corrected column names to match the actual column names in the dataframes
print('Jumlah data informasi destinasi wisata: ', len(wisata.Place_Id.unique()))
print('Jumlah data penilaian oleh pengguna: ', len(rating.Place_Id.unique()))
print('Jumlah data pengguna: ', len(user.User_Id.unique()))
print('Jumlah data paket wisata: ', len(package.Package.unique()))

"""Mengimpor berbagai library yang dibutuhkan untuk pemrosesan data, visualisasi, machine learning, dan evaluasi model. Selain itu juga menampilkan jumlah data pada masing-masing file csv

# Univariate Exploratory Data Analysis

Variabel-variabel pada dataset adalah sebagai berikut:
- wisata: merupakan berbagai tempat wisata yang ada di Indonesia
- rating : merupakan penilaian dari setiap tempat wisata oleh pengguna
- user : data pengguna
- package : merupakan paket wisata yang ada di Indonesia dan dapat dijadikan referensi tambahan

## Variabel Wisata
"""

wisata.info()

"""Untuk melihat informasi dari variabel wisata"""

wisata.head()

"""Untuk melihat seluruh entry unik pada variabel wisata"""

# Membuang kolom yang tidak dipakai
wisata = wisata.drop(['Unnamed: 11','Unnamed: 12'],axis=1)
wisata.head(5)

"""Menghapus kolom yang tidak akan terpakai dan memiliki missing value banyak"""

wisata.isnull().sum()

"""Menampilkan missing value yang terdapat pada variabel wisata

## Variable Rating
"""

rating.info()

"""Untuk melihat informasi dari variabel rating"""

rating.head()

"""Untuk melihat seluruh data rating yang terdiri dari 3 kolom"""

rating.isnull().sum()

"""Melihat seluruh missing value yang terdapat pada variabel rating"""

rating.describe()

"""Menunjukkan count, mean, std, min, dan lainnya pada variabel rating"""

print('Jumlah User_ID: ', len(rating.User_Id.unique()))
print('Jumlah Place_ID: ', len(rating.Place_Id.unique()))
print('Jumlah data rating: ', len(rating))

"""Menampilkan jumlah pengguna, tempat wisata, dan data rating yang ada

## Variabel Pengguna

Seperti yang telah dibahas sebelumnya, profile pengguna kadang diperlukan untuk memahami pola preferensi terhadap suatu item.
"""

print(user.shape)

"""Mengetahui jumlah baris dan kolom dalam  DataFrame user"""

user.head()

"""Menampilkan beberapa baris pertama dari variabel pengguna. Ini sangat berguna saat ingin melihat gambaran awal isi data tanpa menampilkan semuanya"""

user.isnull().sum()

"""Menampilkan missing value yang terdapat pada variabel Pengguna

## Variabel Package
"""

package.info()

"""Menunjukkan informasi pada variabel package"""

package.head()

"""Menunjukkan beberapa baris pertama dari variabel package"""

package.isnull().sum()

"""Menampilkan missing value pada variabel package

# Data Preprocessing

## Menggabungkan Variabel Wisata, Pengguna, dan Rating
"""

# Menggabungkan seluruh Place_Id pada kategori Wisata dan Rating
wisata_all =np.concatenate((
    wisata.Place_Id.unique(),
    rating.Place_Id.unique()
))

wisata_all = np.sort(np.unique(wisata_all))

print(f"Total wisata: {len(wisata_all)}")

"""Melakukan penggabungan placeId pada variabel wisata dan rating"""

# Mengurutkan data dan menghapus data yang sama
wisata_all = np.sort(np.unique(wisata_all))

print('Jumlah seluruh data wisata : ', len(wisata_all))

"""Mengurutkan data dan menghapus data duplikat"""

wisata_rate = rating
wisata_rate

"""Menampilkan informasi mengenai wisata_rate"""

wisata_all = pd.merge(wisata_rate, wisata[["Place_Id", "Place_Name", "Description", "City", "Category"]],on='Place_Id', how='left')
wisata_all

"""Menggabungkan wisata_rate dengan wisata"""

wisata_all['city_category'] = wisata_all[['City','Category']].agg(' '.join,axis=1)
wisata_all

"""Menambah kolom city_category dari kolom city dan category

# Data Preparation

## Mengatasi Missing Value
"""

# Mengecek missing value pada dataframe wisata_all
wisata_all.isnull().sum()

"""Mengecek kembali missing value pada dataframe wisata_all

## Membuat Variabel Preparation
"""

# Membuat variabel preparation yang berisi dataframe wisata_all kemudian mengurutkan berdasarkan placeID
preparation = wisata_all
preparation.sort_values('Place_Id')

"""Membuat variabel preparation yang berisi dataframe wisata_all kemudian mengurutkan berdasarkan placeID

"""

# Membuang data duplikat pada variabel preparation
preparation = wisata_all.drop_duplicates('Place_Id')
preparation

"""Membuang seluruh data duplikat yang ada pada variabel preparation"""

from os import name
# Mengonversi data series ‘placeID’ menjadi dalam bentuk list
place_id = preparation['Place_Id'].tolist()

# Mengonversi data series ‘Name’ menjadi dalam bentuk list
place_name = preparation['Place_Name'].tolist()

# Mengonversi data series ‘Category’ menjadi dalam bentuk list
place_category = preparation['Category'].tolist()

# Mengonversi data series 'Description' menjadi dalam bentuk list
place_desc = preparation['Description'].tolist()

# Mengonversi data series 'City' menjadi dalam bentuk list
place_city = preparation['City'].tolist()

# Mengonversi data series 'City_Category' menjadi dalam bentuk list
city_category = preparation['city_category'].tolist()

print(len(place_id))
print(len(place_name))
print(len(place_category))
print(len(place_desc))
print(len(place_city))
print(len(city_category))

"""Melakukan konversi data series menjadi list. Dalam hal ini menggunakan fungsi tolist() dari library numpy."""

# Membuat dictionary untuk data ‘resto_id’, ‘resto_name’, dan ‘cuisine’
wisata_new = pd.DataFrame({
    "id":place_id,
    "name":place_name,
    "category":place_category,
    "description":place_desc,
    "city":place_city,
    "city_category":city_category
})

wisata_new

"""Membuat `dictionary` untuk menentukan pasangan key-value"""

print(preparation.columns)

"""Menampilkan kolom pada preparation"""

# Step 1: Hitung jumlah rating per Place_Id
top_10 = wisata_new['id'].value_counts().head(10).reset_index()
top_10.columns = ['Place_Id', '']

# Step 2: Gabungkan dengan nama tempat wisata
top_10 = pd.merge(top_10, preparation[['Place_Id', 'Place_Name']], how='left', on='Place_Id')

# Step 3: Visualisasi
plt.figure(figsize=(10, 6))
sns.barplot(data=top_10, y='Place_Name', x='Place_Id', palette='magma')
plt.title('10 Tempat Wisata dengan Rating Terbanyak', fontsize=14, pad=15)
plt.xlabel('Jumlah Rating')
plt.ylabel('Nama Tempat Wisata')
plt.tight_layout()
plt.show()

"""Menghitung jumlah Place_Id, Menggabungkan dengan nama wisata, serta memvisualisasikannya"""

sns.countplot(y='Category', data=preparation)
plt.title('Perbandingan Jumlah Kategori Wisata di Kota Yogyakarta', pad=20)
plt.show()

"""Menampilkan perbandingan jumlah kategori wisata di Yogyakarta"""

plt.figure(figsize=(5,3))
sns.boxplot(user['Age']);
plt.title('Distribusi Usia Pengguna', pad=20)
plt.show()

"""Visualisasi Distribusi Usia Pengguna"""

plt.figure(figsize=(7,3))
sns.boxplot(wisata['Price'])
plt.title('Distribusi Harga Masuk Wisata di Yogyakarta', pad=20)
plt.show()

"""Visualisasi Distribusi Harga Masuk Wisata di Ypgyakarta"""

# Distribusi asal kota pengguna
askot = user['Location'].apply(lambda x : x.split(',')[0])
plt.figure(figsize=(8,6))
sns.countplot(y=askot)
plt.title('Jumlah Asal Kota Pengguna')
plt.show()

"""Visualisai Distribusi Jumlah Asal Kota Pengguna

# Model Development Content Based Filtering
"""

data = wisata_new
data.sample(5)

"""Menampilkan data sampel wisata_new

## TF-IDF Vectorizer

$$ TF-IDF = Term Frequency – Inverse Document Frequency $$

Mengubah teks menjadi vektor numerik berdasarkan pentingnya kata dalam dokumen dan seluruh koleksi data

Teknik tersebut juga akan digunakan pada sistem rekomendasi untuk menemukan representasi fitur penting dari setiap kategori wisata.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data city_category
tf.fit(data['city_category'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

print("Features Name: ", list(tf.vocabulary_.keys()))

"""Melakukan inisialisasi TfidVectorizer, menghitung idf pada city_category, serta mapping array dari fitur index integer ke fitur nama"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['city_category'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Perhatikanlah, matriks yang kita miliki berukuran (437, 15). Nilai 437 merupakan ukuran data dan 15 merupakan matrik kategori city_category."""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense"""

# Membuat dataframe untuk melihat tf-idf matrix

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=list(tf.vocabulary_.keys()),
    index=data.name
).sample(10)

"""Membuat dataframe untuk melihat tf-idf matrix

## Cosine Similarity

Cosine Similarity mengukur kemiripan antara dua vektor berdasarkan sudut (bukan panjangnya).

Nilai berada di antara `-1` hingga `1`:

`1` → sangat mirip (arah vektor sama)

`0` → tidak mirip (tegak lurus)

`-1` → berlawanan (jarang terjadi di NLP)

**Rumus Cosine Similarity**

$$
\text{cosine_similarity}(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}
$$

Keterangan:
- $ A \cdot B $: dot product antara vektor A dan B  
- $ \|A\| $: panjang (norma) dari vektor A  
- $ \|B\| $: panjang (norma) dari vektor B
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Menghitung cosine similarity pada matrix tf-idf"""

# Membuat dataframe dari variabel cosine_sim
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['name'], columns=data['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap tempat
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Membuat dataframe dari variabel cosine_sim dan melihat similarity pada setiap tempat

## Mendapatkan Rekomendasi
"""

def rekomendasi_wisata(place_name, similarity_data=cosine_sim_df, items=data[['name','category','description','city']], k=5):

      # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
      # Dataframe diubah menjadi numpy
      # Range(start, stop, step)
      index = similarity_data.loc[:,place_name].to_numpy().argpartition(
          range(-1, -k, -1))

      # Mengambil data dengan similarity terbesar dari index yang ada
      closest = similarity_data.columns[index[-1:-(k+2):-1]]

      # Drop place_name agar nama tempat wisata yang dicari tidak muncul dalam daftar rekomendasi
      closest = closest.drop(place_name, errors='ignore')

      return pd.DataFrame(closest).merge(items).head(k)

"""Dengan menggunakan argpartition, kita mengambil sejumlah nilai `k` tertinggi dari similarity data (dalam kasus ini: `dataframe cosine_sim_df`). Kemudian, mengambil data dari bobot (tingkat kesamaan) tertinggi ke terendah. Lalu menghapus `place_name` yang yang dicari agar tidak muncul dalam daftar rekomendasi."""

# Mendapatkan rekomendasi Candi yang mirip dengan Candi Prambanan
rekomendasi_wisata('Candi Prambanan')

"""Menampilkan hasil rekomendasi untuk Candi yang mirip dengan Candi Prambanan"""

# Mendapatkan rekomendasi Museum yang mirip dengan Museum Geologi Bandung
rekomendasi_wisata('Museum Geologi Bandung')

"""Menampilkan hasil rekomendasi untuk Museum yang mirip dengan Museum Geologi Bandung

## Metrik Evaluasi

### Precision

Precision **mengukur seberapa banyak rekomendasi yang benar dari total yang diberikan**.

$$
\text{Precision@k} = \frac{\text{Jumlah item relevan dalam top-}k}{k}
$$


Fokus: Akurasi dari hasil yang ditampilkan ke user.

Hasil: Sistem merekomendasikan 5 tempat wisata, dan 4 sesuai selera user berdasarkan input →

```
Input: 'Candi Prambanan', category = Budaya
Dataset:
0 - Cqndi Batu Ruko                        → Budaya ✅
1 - Taman Budaya Yogyakarta                → Budaya ✅
2 - Monumen Yogya Kembali                  → Budaya ✅
3 - Museum Benteng Vredeburg Yogyakarta    → Budaya ✅
4 - Bukit Panguk Kediwung                  → Budaya ✅
```

$$
Precision@5=\dfrac{5}{5}= 1.00
$$

# Model Development dengan Collaborative Filtering
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""Kita akan menerapkan teknik collaborative filtering untuk membuat sistem rekomendasi. Teknik ini membutuhkan data rating dari user."""

# Membaca dataset
df = rating
df

"""Membaca data set rating

## Data Preparation

Pada tahap ini, perlu melakukan persiapan data untuk menyandikan (encode) fitur `user` dan `placeID` ke dalam indeks integer.
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['User_Id'].unique().tolist()
print('List User_Id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded User_Id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke User_Id: ', user_encoded_to_user)

"""Mengubah user_Id menjadi list tanpa nilai yang sama, melakukan encoding, dam proses encoding angka ke user_Id"""

# Mengubah placeID menjadi list tanpa nilai yang sama
place_ids = df['Place_Id'].unique().tolist()

# Melakukan proses encoding placeID
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}

# Melakukan proses encoding angka ke placeID
place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}

"""Mengubah place_Id menjadi list tanpa nilai yang sama, melakukan encoding, dam proses encoding angka ke place_Id"""

# Mapping userID ke dataframe user
df['user'] = df['User_Id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe resto
df['place'] = df['Place_Id'].map(place_to_place_encoded)

"""Melakukan pemetaan  `userID` dan `placeID` ke dataframe yang berkaitan."""

# Mendapatkan jumlah user
num_user = len(user_to_user_encoded)
print(num_user)

# Mendapatkan jumlah wisata
num_place = len(place_encoded_to_place)
print(num_place)

# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['Place_Ratings'])

# Nilai maksimal rating
max_rating = max(df['Place_Ratings'])

print('Number of User: {}, Number of Wisata: {}, Min Rating: {}, Max Rating: {}'.format(
    num_user, num_place, min_rating, max_rating
))

"""Mendapatkan jumlah user dan jumlah wisata, mengubah rating menjadi float, dan mengidentifikasi nilai minimum dan maksumum pada rating.

## Membagi Data untuk Training dan Validasi
"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""Mengacak datanya terlebih dahulu agar distribusinya menjadi random

Selain itu kita juga melakukan proses normalisasi untuk rating dengan menggunakan metode `MinMax` normalization agar nantinya model lebih mudah untuk dilatih
"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['user', 'place']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Selanjutnya, melakukan pembagian data train dan validasi dengan komposisi 80:20.

## Proses Training
"""

class RecommenderNet(tf.keras.Model):

  # Melakukan Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_user = num_user
    self.num_place = num_place
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_user,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.place_embedding = layers.Embedding( # layer embeddings resto
        num_place,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.place_bias = layers.Embedding(num_resto, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    place_vector = self.place_embedding(inputs[:, 1]) # memanggil layer embedding 3
    place_bias = self.place_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_place = tf.tensordot(user_vector, place_vector, 2)

    x = dot_user_place + user_bias + place_bias

    return tf.nn.sigmoid(x)

"""Pada tahap ini, model menghitung skor kecocokan antara pengguna dan tempat wisata dengan **teknik embedding**. Selanjutnya, lakukan operasi **perkalian dot product** antara embedding user dan place. Selain itu, kita juga dapat menambahkan *bias* untuk setiap user dan place. Skor kecocokan ditetapkan dalam skala [0,1] dengan fungsi **aktivasi sigmoid**."""

model = RecommenderNet(num_user, num_place, 100) # inisialisasi model
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model ini menggunakan Binary Crossentropy untuk menghitung loss function, Adam (Adaptive Moment Estimation) sebagai optimizer, dan root mean squared error (RMSE) sebagai metrics evaluation."""

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 50,
    validation_data = (x_val, y_val)
)

"""Melakukan training

## Visualisasi Metrik
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Perhatikanlah, proses training model cukup smooth dan model konvergen pada epochs sekitar 50. Dari proses ini, diperoleh nilai error akhir sebesar sekitar 0.31 dan error pada data validasi sebesar 0.35. Nilai tersebut cukup bagus untuk sistem rekomendasi.

## Mendapatkan Rekomendasi Wisata

Untuk mendapatkan rekomendasi tempat wisata, diambil sampel user secara acak dan definisikan variabel `place_not_visited` yang merupakan daftar wisata yang belum pernah dikunjungi oleh pengguna. Rating digunakan untuk membuat rekomendasi wisata yang mungkin cocok untuk pengguna.
"""

place_df = wisata_new
df = pd.read_csv('tourism_rating.csv')

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

# Operator bitwise
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""Mengambil sample user dan menggunakan variabel place_not_visited pada operator bitwise"""

ratings = model.predict(user_place_array).flatten()
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_place_ids = [ place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices]

print('Menampilkan rekomnendasi wisata untuk pengguna: {}'.format(user_id))
print('===' * 9)
print('Tempat wisata dengan rating tertinggi dari pengguna')
print('----' * 8)

top_place_user = (
    place_visited_by_user.sort_values(by = 'Place_Ratings',ascending=False )
    .head(5)
    .Place_Id.values
)

place_df_rows = place_df[place_df['id'].isin(top_place_user)]
pd.DataFrame(place_df_rows)

"""Menampilkan  jumlah rekomendasi wisata untuk pengguna dan tempat wisata yang memiliki rating tertinggi"""

print('----' * 8)
print('Top 10 Rekomendasi Wisata')
print('----' * 8)

recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
recommended_place

"""Menampilkan Top 10 Rekomendasi Wisata

Model untuk menampilkan top 10 rekomendasi tempat wisata telah selesai dibuat dan model ini dapat digunakan untuk menampilkan rekomendasi kepada user sehingga dapat meningkatkan minat pengguna terhadap pariwisata di Indonesia
"""